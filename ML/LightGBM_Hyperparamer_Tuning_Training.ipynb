{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf24f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import dalex as dx\n",
    "import lightgbm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import shap\n",
    "import sys\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,balanced_accuracy_score,f1_score,matthews_corrcoef,roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a570d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definitions of path\n",
    "MODEL_DIR = os.path.join(\"./LightGBM/\")\n",
    "path_train_data=os.path.join(\"../data/trainValid.csv\")\n",
    "path_test_data=os.path.join(\"../data/test.csv\")\n",
    "path_test_AIBL=os.path.join(\"../data/AIBL.csv\")\n",
    "path_test_OASIS=os.path.join(\"../data/OASIS.csv\")\n",
    "filenameCSV=os.path.join(\"./LightGBM/LightGBM_hyperparameter_tuning.csv\")\n",
    "filename_predictions_for_platt_scaling=os.path.join(\"./LightGBM/LightGBM_predictions_for_platt_scaling.csv\")\n",
    "mapping_ML_DL=os.path.join(\"../additional_data/Mapping_DKT_Regions_Deep_ML_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a0ecf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load ADNI train and test data\n",
    "test=pd.read_csv(path_test_data,index_col=\"PTID\")\n",
    "trainValidMerged=pd.read_csv(path_train_data,index_col=\"PTID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dc11f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if model directory not exists create model directory\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eddd8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter tuning (grid-search), 5-fold CV\n",
    "for n_estimators in [100,200,300,400,500]:\n",
    "    for learning_rate in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "        for colsample_bytree  in [0.5,0.6,0.7,0.8,0.9]:\n",
    "            for max_depth in [5,10,15,20]:\n",
    "                for subsample in [0.5,0.6,0.7,0.8,0.9]:\n",
    "                    for num_leaves in [10,20,30,40,50]:\n",
    "                        kf = StratifiedKFold(n_splits=5,shuffle=True,random_state=101)\n",
    "                        cvIt=0\n",
    "                        for trainCross, validCross in kf.split(trainValidMerged,trainValidMerged.DX):\n",
    "                            cvIt+=1\n",
    "                            #identify training and validation data\n",
    "                            training=trainValidMerged.iloc[trainCross]\n",
    "                            valid=trainValidMerged.iloc[validCross]\n",
    "                            #change format of training data\n",
    "                            Y_train=pd.get_dummies(training.DX,drop_first=True).to_numpy().squeeze()\n",
    "                            X_train=training.drop([\"DX\"],axis=1).to_numpy()\n",
    "                            #change format of validation data\n",
    "                            Y_valid=pd.get_dummies(valid.DX,drop_first=True).to_numpy().squeeze()\n",
    "                            X_valid=valid.drop([\"DX\"],axis=1).to_numpy()\n",
    "                            #fit scaler for training dataset\n",
    "                            scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "                            #apply scaling for training and validation data\n",
    "                            X_train_pre=scaler.transform(X_train)\n",
    "                            X_valid_pre=scaler.transform(X_valid)\n",
    "                            #train model on training data\n",
    "                            model = lightgbm.LGBMClassifier(n_estimators=n_estimators,learning_rate=learning_rate,colsample_bytree=colsample_bytree,max_depth=max_depth,subsample=subsample,num_leaves=num_leaves,random_state=42,n_jobs =2)\n",
    "                            model.fit(X_train_pre, Y_train)\n",
    "                            #predict results on validation data\n",
    "                            predictions_val=model.predict(X_valid_pre)\n",
    "                            #calculate accuracy score on validation dataset\n",
    "                            acc=accuracy_score(Y_valid, predictions_val)\n",
    "                            #save results for CV iteration to file\n",
    "                            d = {'n_estimators': [n_estimators], 'learning_rate': [learning_rate],'colsample_bytree':[colsample_bytree],'max_depth':[max_depth],'subsample':[subsample],'num_leaves':[num_leaves],'CV':[cvIt], \"Epoch-Accuracy\":[acc*100]}\n",
    "                            df = pd.DataFrame(data=d)\n",
    "                            if os.path.isfile(filenameCSV):\n",
    "                                df.to_csv(filenameCSV, mode='a', header=False)\n",
    "                            else:\n",
    "                                df.to_csv(filenameCSV, mode='w', header=True)\n",
    "                            #save model\n",
    "                            filename=MODEL_DIR+\"model_\"+str(n_estimators)+\"_\"+str(learning_rate)+\"_\"+str(colsample_bytree)+\"_\"+str(max_depth)+\"_\"+str(subsample)+\"_\"+str(num_leaves)+\"_\"+str(cvIt)+\".sav\"\n",
    "                            pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9c5cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify hyperparameters that achieve best mean accuracy during CV\n",
    "#load dataset\n",
    "datasetMonai=pd.read_csv(filenameCSV,index_col=0)\n",
    "datasetMonaiTest=datasetMonai.drop([\"Epoch-Accuracy\"], axis=1)\n",
    "#remove duplicate datapoints (e.g. if the pipeline was run multiple time, the last entry is kept)\n",
    "datasetMonai=datasetMonai[~datasetMonaiTest.duplicated(keep=\"last\")]\n",
    "#group CV results by hyperparameters\n",
    "listCV=datasetMonai.groupby([\"n_estimators\",\"learning_rate\",\"colsample_bytree\",\"max_depth\",\"subsample\",\"num_leaves\"])\n",
    "listCV = [group for _, group in listCV]\n",
    "#create new data frame\n",
    "column_names = [\"n_estimators\",\"learning_rate\",\"colsample_bytree\",\"max_depth\",\"subsample\",\"num_leaves\", \"CV-Accuracy\",\"CV-Accuracy_sd\"]\n",
    "dfGes = pd.DataFrame(columns = column_names)\n",
    "#for each hyperparameter combination calculate mean and sd of validation accuracy\n",
    "for i in listCV:\n",
    "    row_a={'n_estimators': i[\"n_estimators\"].iloc[0],'learning_rate': i[\"learning_rate\"].iloc[0],'colsample_bytree': i[\"colsample_bytree\"].iloc[0],'max_depth': i[\"max_depth\"].iloc[0],'subsample': i[\"subsample\"].iloc[0],'num_leaves': i[\"num_leaves\"].iloc[0], 'CV-Accuracy':i[\"Epoch-Accuracy\"].mean(), 'CV-Accuracy_sd':i[\"Epoch-Accuracy\"].std()}\n",
    "    row_df = pd.DataFrame(row_a,index=[0])\n",
    "    dfGes = pd.concat([dfGes,row_df])\n",
    "#sort data frame by mean CV accuracy\n",
    "dfGes=dfGes.sort_values(by=['CV-Accuracy'])\n",
    "dfGes=dfGes.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca82a645",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83723a80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea1242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract best hyperparameters\n",
    "n_estimators=dfGes.iloc[dfGes.shape[0]-1][\"n_estimators\"]\n",
    "learning_rate=dfGes.iloc[dfGes.shape[0]-1][\"learning_rate\"]\n",
    "colsample_bytree=dfGes.iloc[dfGes.shape[0]-1][\"colsample_bytree\"]\n",
    "max_depth=dfGes.iloc[dfGes.shape[0]-1][\"max_depth\"]\n",
    "subsample=dfGes.iloc[dfGes.shape[0]-1][\"subsample\"]\n",
    "num_leaves=dfGes.iloc[dfGes.shape[0]-1][\"num_leaves\"]\n",
    "#extract best mean CV accuracy and sd \n",
    "cv_acc_mean=dfGes.iloc[dfGes.shape[0]-1][\"CV-Accuracy\"]\n",
    "cv_acc_sd=dfGes.iloc[dfGes.shape[0]-1][\"CV-Accuracy_sd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1117eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate predictions of model with best hyperparameters during CV for Platt scaling\n",
    "kf = StratifiedKFold(n_splits=5,shuffle=True,random_state=101)\n",
    "cvIt=0\n",
    "for trainCross, validCross in kf.split(trainValidMerged,trainValidMerged.DX):\n",
    "    cvIt+=1\n",
    "    #identify training and validation datasets\n",
    "    training=trainValidMerged.iloc[trainCross]\n",
    "    valid=trainValidMerged.iloc[validCross]\n",
    "    #change format of training data\n",
    "    Y_train=pd.get_dummies(training.DX,drop_first=True).to_numpy().squeeze()\n",
    "    X_train=training.drop([\"DX\"],axis=1).to_numpy()\n",
    "    #change format of validation data\n",
    "    Y_valid=pd.get_dummies(valid.DX,drop_first=True).to_numpy().squeeze()\n",
    "    X_valid=valid.drop([\"DX\"],axis=1).to_numpy()\n",
    "    #fit scaler for training dataset\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    #apply scaling for training and validation data\n",
    "    X_train_pre=scaler.transform(X_train)\n",
    "    X_valid_pre=scaler.transform(X_valid)\n",
    "    #load trained model\n",
    "    filename=MODEL_DIR+\"model_\"+str(n_estimators)+\"_\"+str(learning_rate)+\"_\"+str(colsample_bytree)+\"_\"+str(max_depth)+\"_\"+str(subsample)+\"_\"+str(num_leaves)+\"_\"+str(cvIt)+\".sav\"\n",
    "    model = pickle.load(open(filename, 'rb'))\n",
    "    #calculate predictions for validation dataset\n",
    "    predictions_test = model.predict(X_valid_pre)\n",
    "    predictions_test_prob=model.predict_proba(X_valid_pre)[:, 1]\n",
    "    #save predictions for validation dataset\n",
    "    predictionsRes=pd.DataFrame({\"labels\":Y_valid,\"predictions_bin\":predictions_test,\"predictions_prob\":predictions_test_prob})\n",
    "    if os.path.isfile(filename_predictions_for_platt_scaling):\n",
    "        predictionsRes.to_csv(filename_predictions_for_platt_scaling, mode='a', header=False)\n",
    "    else:\n",
    "        predictionsRes.to_csv(filename_predictions_for_platt_scaling, mode='w', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e2ef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate results for ADNI test dataset\n",
    "#change format of test dataset\n",
    "Y_test=pd.get_dummies(test.DX,drop_first=True).to_numpy().squeeze()\n",
    "X_test=test.drop([\"DX\"],axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f93d037",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change format of training dataset\n",
    "Y_train=pd.get_dummies(trainValidMerged.DX,drop_first=True).to_numpy().squeeze()\n",
    "X_train=trainValidMerged.drop([\"DX\"],axis=1).to_numpy()\n",
    "#fit scaler for training dataset\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "#apply scaling for training and ADNI test dataset\n",
    "X_train_pre=scaler.transform(X_train)\n",
    "X_test_pre=scaler.transform(X_test)\n",
    "#train final model on entire training dataset\n",
    "model = lightgbm.LGBMClassifier(n_estimators=n_estimators,learning_rate=learning_rate,colsample_bytree=colsample_bytree,max_depth=max_depth,subsample=subsample,num_leaves=num_leaves,random_state=42,n_jobs =2)\n",
    "model.fit(X_train_pre, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d86594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define calibration model\n",
    "class MyClassifier(BaseEstimator):\n",
    "    def __init__(self, estimator1=None, estimator2=None):\n",
    "        self.estimator1 = estimator1\n",
    "        self.estimator2 = estimator2\n",
    "    def fit(self, X, y):\n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        # Store the classes seen during fit\n",
    "        self.classes_ = unique_labels(y)\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Input validation\n",
    "        X = check_array(X)\n",
    "        pred1=self.estimator1.predict_proba(X)\n",
    "        pred1=np.expand_dims(pred1[:,1], axis=1)\n",
    "        pred2=self.estimator2.predict(pred1)\n",
    "        return pred2\n",
    "    def predict_proba(self, X):\n",
    "        # Input validation\n",
    "        X = check_array(X)\n",
    "        pred1=self.estimator1.predict_proba(X)\n",
    "        pred1=np.expand_dims(pred1[:,1], axis=1)\n",
    "        pred2=self.estimator2.predict_proba(pred1)\n",
    "        return pred2\n",
    "#load CV calibrations for Platt scaling\n",
    "pred=pd.read_csv(filename_predictions_for_platt_scaling)\n",
    "test = np.expand_dims(pred.predictions_prob.to_numpy(), axis=1)\n",
    "#train logistic regression model on CV calibrations for Platt scaling\n",
    "clf = LogisticRegression(random_state=0).fit(test, pred.labels)\n",
    "clfTest=MyClassifier(model,clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e7e9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict calibrated results for ADNI test set\n",
    "predictions_test = clfTest.predict(X_test_pre)\n",
    "predictions_test_prob=clfTest.predict_proba(X_test_pre)[:, 1]\n",
    "#calculate metrics\n",
    "acc_adni_test=accuracy_score(Y_test, predictions_test)\n",
    "bacc_adni_test=balanced_accuracy_score(Y_test, predictions_test)\n",
    "f1_adni_test=f1_score(Y_test, predictions_test, average='macro')\n",
    "mcc_adni_test=matthews_corrcoef(Y_test, predictions_test)\n",
    "auroc_adni_test=roc_auc_score(Y_test, predictions_test_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7c14db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load AIBL test dataset\n",
    "AIBL=pd.read_csv(path_test_AIBL,index_col=\"PTID\")\n",
    "#change format of AIBL dataset\n",
    "Y_AIBL=pd.get_dummies(AIBL.DX,drop_first=True).to_numpy().squeeze()\n",
    "X_AIBL=AIBL.drop([\"DX\"],axis=1).to_numpy()\n",
    "#apply scaling for AIBL test dataset\n",
    "X_AIBL_pre=scaler.transform(X_AIBL)\n",
    "#predict calibrated results for AIBL test set\n",
    "predictions_test = clfTest.predict(X_AIBL_pre)\n",
    "predictions_test_prob=clfTest.predict_proba(X_AIBL_pre)[:, 1]\n",
    "#calculate metrics for AIBL\n",
    "acc_aibl_test=accuracy_score(Y_AIBL, predictions_test)\n",
    "bacc_aibl_test=balanced_accuracy_score(Y_AIBL, predictions_test)\n",
    "f1_aibl_test=f1_score(Y_AIBL, predictions_test, average='macro')\n",
    "mcc_aibl_test=matthews_corrcoef(Y_AIBL, predictions_test)\n",
    "auroc_aibl_test=roc_auc_score(Y_AIBL, predictions_test_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619cd59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load OASIS test dataset\n",
    "OASIS=pd.read_csv(path_test_OASIS,index_col=\"PTID\")\n",
    "#change format of OASIS test dataset\n",
    "Y_OASIS=pd.get_dummies(OASIS.DX,drop_first=True).to_numpy().squeeze()\n",
    "X_OASIS=OASIS.drop([\"DX\"],axis=1).to_numpy()\n",
    "#apply scaling for OASIS test dataset\n",
    "X_OASIS_pre=scaler.transform(X_OASIS)\n",
    "#predict calibrated results for OASIS test set\n",
    "predictions_test = clfTest.predict(X_OASIS_pre)\n",
    "predictions_test_prob=clfTest.predict_proba(X_OASIS_pre)[:, 1]\n",
    "#calculate metrics for OASIS\n",
    "acc_oasis_test=accuracy_score(Y_OASIS, predictions_test)\n",
    "bacc_oasis_test=balanced_accuracy_score(Y_OASIS,predictions_test)\n",
    "f1_oasis_test=f1_score(Y_OASIS, predictions_test, average='macro')\n",
    "mcc_oasis_test=matthews_corrcoef(Y_OASIS, predictions_test)\n",
    "auroc_oasis_test=roc_auc_score(Y_OASIS, predictions_test_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc898942",
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpret ML model\n",
    "#load mapping of features between ML and DL\n",
    "mapping=pd.read_csv(mapping_ML_DL)\n",
    "#identify features which are available for both model types\n",
    "X_train_pre_red=X_train_pre[:,training.drop([\"DX\"],axis=1).columns.isin(mapping.feature_ML)]\n",
    "#identify aspects for features which are available for both model types\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dataNamed=pd.DataFrame(X_train_pre_red,columns=training.drop([\"DX\"],axis=1).columns[training.drop([\"DX\"],axis=1).columns.isin(mapping.feature_ML)])\n",
    "exp = dx.Explainer(dummy_clf, dataNamed, Y_train)\n",
    "asp = dx.Aspect(exp)\n",
    "aspects=asp.get_aspects(h=0.5)\n",
    "#add features only available in ML models (eTIV)\n",
    "notInDeep=training.drop([\"DX\"],axis=1).columns[~training.drop([\"DX\"],axis=1).columns.isin(mapping.feature_ML)]\n",
    "notInDeep=notInDeep.tolist()\n",
    "for value in notInDeep:\n",
    "    aspects[value]=[value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3ca1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate permutation importance for aspects\n",
    "dataNamed=pd.DataFrame(X_train_pre,columns=training.drop([\"DX\"],axis=1).columns)\n",
    "exp = dx.Explainer(clfTest, dataNamed, Y_train)\n",
    "asp = dx.Aspect(exp)\n",
    "mai_asp = asp.model_parts(variable_groups=aspects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f627207",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#calculate SHAP importances for aspects\n",
    "dataNamed=pd.DataFrame(X_train_pre,columns=training.drop([\"DX\"],axis=1).columns)\n",
    "exp = dx.Explainer(clfTest, dataNamed, Y_train)\n",
    "asp = dx.Aspect(exp)\n",
    "df=pd.DataFrame(columns=aspects.keys())\n",
    "for i in range(X_train_pre.shape[0]):\n",
    "    print(i)\n",
    "    mai_asp_shap = asp.predict_parts(X_train_pre[i],variable_groups=aspects, label='for aspects created by user', type='shap', random_state=42,N=1000)\n",
    "    res=mai_asp_shap.result\n",
    "    df=pd.concat([df,pd.DataFrame([res.importance.tolist()],columns=res.aspect_name,index=[trainValidMerged.index[i]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc05982",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize SHAP feature importance plot\n",
    "df_sum=df.abs().sum(axis=0)\n",
    "ax=pd.Series(df_sum,dtype=float).nlargest(10).plot(kind='barh')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel(\"SHAP importance\")\n",
    "ax.set_ylabel(\"Aspects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7db6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize SHAP summary plot\n",
    "training_cal=trainValidMerged.copy()\n",
    "for a in aspects:\n",
    "    for b in aspects[a]:\n",
    "        training_cal[b]=df[a]\n",
    "training_cal_shap=training_cal.drop([\"DX\"],axis=1)\n",
    "training_test=trainValidMerged.drop([\"DX\"],axis=1)\n",
    "columnNamesNew=training_test.columns\n",
    "columnNamesNew=[]\n",
    "for column in trainValidMerged.columns:\n",
    "    for aspect in aspects:\n",
    "        for dfcol in aspects[aspect]:\n",
    "            if(dfcol==column):\n",
    "                if(aspect.startswith(\"aspect\")):\n",
    "                    columnNamesNew.append(column+\" (\"+aspect+\")\")\n",
    "                else:\n",
    "                    columnNamesNew.append(column)\n",
    "\n",
    "shap.summary_plot(training_cal_shap.to_numpy().astype(float),training_test.to_numpy().astype(float),columnNamesNew,show=False)\n",
    "plt.text(-0.4, 20, 'protective')\n",
    "plt.text(0.6, 20, 'progressive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b2e5cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#calculate LIME importances for aspects\n",
    "dataNamed=pd.DataFrame(X_train_pre,columns=training.drop([\"DX\"],axis=1).columns)\n",
    "exp = dx.Explainer(clfTest, dataNamed, Y_train)\n",
    "asp = dx.Aspect(exp)\n",
    "df=pd.DataFrame(columns=aspects.keys())\n",
    "for i in range(X_train_pre.shape[0]):\n",
    "    print(i)\n",
    "    mai_asp_shap = asp.predict_parts(X_train_pre[i],variable_groups=aspects, label='for aspects created by user', type='default', random_state=42,N=1000)\n",
    "    res=mai_asp_shap.result\n",
    "    df=pd.concat([df,pd.DataFrame([res.importance.tolist()],columns=res.aspect_name,index=[trainValidMerged.index[i]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e2b1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize LIME feature importance plot\n",
    "df_sum=df.abs().sum(axis=0)\n",
    "ax=pd.Series(df_sum,dtype=float).nlargest(10).plot(kind='barh')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel(\"LIME importance\")\n",
    "ax.set_ylabel(\"Aspects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfe5770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize LIME summary plot\n",
    "training_cal=trainValidMerged.copy()\n",
    "for a in aspects:\n",
    "    for b in aspects[a]:\n",
    "        training_cal[b]=df[a]\n",
    "training_cal_shap=training_cal.drop([\"DX\"],axis=1)\n",
    "training_test=trainValidMerged.drop([\"DX\"],axis=1)\n",
    "columnNamesNew=training_test.columns\n",
    "columnNamesNew=[]\n",
    "for column in trainValidMerged.columns:\n",
    "    for aspect in aspects:\n",
    "        for dfcol in aspects[aspect]:\n",
    "            if(dfcol==column):\n",
    "                if(aspect.startswith(\"aspect\")):\n",
    "                    columnNamesNew.append(column+\" (\"+aspect+\")\")\n",
    "                else:\n",
    "                    columnNamesNew.append(column)\n",
    "\n",
    "shap.summary_plot(training_cal_shap.to_numpy().astype(float),training_test.to_numpy().astype(float),columnNamesNew,show=False)\n",
    "plt.text(-0.4, 20, 'protective')\n",
    "plt.text(0.6, 20, 'progressive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54062205",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"n_estimators: {n_estimators},\\n learning_rate: {learning_rate},\\n colsample_bytree: {colsample_bytree},\\n max_depth: {max_depth},\\n subsample: {subsample},\\n num_leaves: {num_leaves},\\n Mean CV-Accuracy: {round(cv_acc_mean,2)},\\n SD CV-Accuracy: {round(cv_acc_sd,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307b9645",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy (ADNI test set): {round(acc_adni_test*100,2)},\\n balanced-accuracy (ADNI test set): {round(bacc_adni_test*100,2)},\\n Macro-averaging F1-score (ADNI test set): {round(f1_adni_test*100,2)},\\n MCC (ADNI test set): {round(mcc_adni_test,3)},\\n AUROC (ADNI test set): {round(auroc_adni_test*100,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20755805",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy (AIBL test set): {round(acc_aibl_test*100,2)},\\n balanced-accuracy (AIBL test set): {round(bacc_aibl_test*100,2)},\\n Macro-averaging F1-score (AIBL test set): {round(f1_aibl_test*100,2)},\\n MCC (AIBL test set): {round(mcc_aibl_test,3)},\\n AUROC (AIBL test set): {round(auroc_aibl_test*100,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b90815",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy (OASIS test set): {round(acc_oasis_test*100,2)},\\n balanced-accuracy (OASIS test set): {round(bacc_oasis_test*100,2)},\\n Macro-averaging F1-score (OASIS test set): {round(f1_oasis_test*100,2)},\\n MCC (OASIS test set): {round(mcc_oasis_test,3)},\\n AUROC (OASIS test set): {round(auroc_oasis_test*100,2)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
