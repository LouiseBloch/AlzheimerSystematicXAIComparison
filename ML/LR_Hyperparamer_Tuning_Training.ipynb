{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16642c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import dalex as dx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import shap\n",
    "import sys\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,balanced_accuracy_score,f1_score,matthews_corrcoef,roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be6bfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definitions of path\n",
    "MODEL_DIR = os.path.join(\"./LR/\")\n",
    "path_train_data=os.path.join(\"../data/trainValid.csv\")\n",
    "path_test_data=os.path.join(\"../data/test.csv\")\n",
    "path_test_AIBL=os.path.join(\"../data/AIBL.csv\")\n",
    "path_test_OASIS=os.path.join(\"../data/OASIS.csv\")\n",
    "filenameCSV=os.path.join(\"./LR/LR_hyperparameter_tuning\")\n",
    "filename_predictions_for_platt_scaling=\"./LR/LR_predictions_for_platt_scaling.csv\"\n",
    "mapping_ML_DL=os.path.join(\"../additional_data/Mapping_DKT_Regions_Deep_ML_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d72f694",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load ADNI train and test data\n",
    "test=pd.read_csv(path_test_data,index_col=\"PTID\")\n",
    "trainValidMerged=pd.read_csv(path_train_data,index_col=\"PTID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e41430",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if model directory not exists create model directory\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a06517",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter tuning (grid-search), 5-fold CV\n",
    "kf = StratifiedKFold(n_splits=5,shuffle=True,random_state=101)\n",
    "cvIt=0\n",
    "for trainCross, validCross in kf.split(trainValidMerged,trainValidMerged.DX):\n",
    "    cvIt+=1\n",
    "    #identify training and validation data\n",
    "    training=trainValidMerged.iloc[trainCross]\n",
    "    valid=trainValidMerged.iloc[validCross]\n",
    "    #change format of training data\n",
    "    Y_train=pd.get_dummies(training.DX,drop_first=True).to_numpy().squeeze()\n",
    "    X_train=training.drop([\"DX\"],axis=1).to_numpy()\n",
    "    #change format of validation data\n",
    "    Y_valid=pd.get_dummies(valid.DX,drop_first=True).to_numpy().squeeze()\n",
    "    X_valid=valid.drop([\"DX\"],axis=1).to_numpy()\n",
    "    #fit scaler for training dataset\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    #apply scaling for training and validation data\n",
    "    X_train_pre=scaler.transform(X_train)\n",
    "    X_valid_pre=scaler.transform(X_valid)\n",
    "    #train model on training data\n",
    "    model = LogisticRegression(random_state=666)\n",
    "    model.fit(X_train_pre, Y_train)\n",
    "    #predict results on validation data\n",
    "    predictions_val=model.predict(X_valid_pre)\n",
    "    #calculate accuracy score on validation dataset\n",
    "    acc=accuracy_score(Y_valid, predictions_val)\n",
    "    #save results for CV iteration to file\n",
    "    d = {'CV':[cvIt], \"Epoch-Accuracy\":[acc*100]}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    if os.path.isfile(filenameCSV):\n",
    "        df.to_csv(filenameCSV, mode='a', header=False)\n",
    "    else:\n",
    "        df.to_csv(filenameCSV, mode='w', header=True)\n",
    "    #save model\n",
    "    filename=MODEL_DIR+\"model_\"+str(cvIt)+\".sav\"\n",
    "    pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396e0e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify mean accuracy during CV\n",
    "#load dataset\n",
    "datasetMonai=pd.read_csv(filenameCSV,index_col=0)\n",
    "datasetMonaiTest=datasetMonai.drop([\"Epoch-Accuracy\"], axis=1)\n",
    "#remove duplicate datapoints (e.g. if the pipeline was run multiple time, the last entry is kept)\n",
    "datasetMonai=datasetMonai[~datasetMonaiTest.duplicated(keep=\"last\")]\n",
    "#extract mean CV accuracy and sd \n",
    "cv_acc_mean=datasetMonai[\"Epoch-Accuracy\"].mean()\n",
    "cv_acc_sd=datasetMonai[\"Epoch-Accuracy\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e82784",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate results for ADNI test dataset\n",
    "#change format of test dataset\n",
    "Y_test=pd.get_dummies(test.DX,drop_first=True).to_numpy().squeeze()\n",
    "X_test=test.drop([\"DX\"],axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb03e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change format of training dataset\n",
    "Y_train=pd.get_dummies(trainValidMerged.DX,drop_first=True).to_numpy().squeeze()\n",
    "X_train=trainValidMerged.drop([\"DX\"],axis=1).to_numpy()\n",
    "#fit scaler for training dataset\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "#apply scaling for training and ADNI test dataset\n",
    "X_train_pre=scaler.transform(X_train)\n",
    "X_test_pre=scaler.transform(X_test)\n",
    "#train final model on entire training dataset\n",
    "model = LogisticRegression(random_state=666)\n",
    "model.fit(X_train_pre, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d95c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict calibrated results for ADNI test set\n",
    "predictions_test = model.predict(X_test_pre)\n",
    "predictions_test_prob=model.predict_proba(X_test_pre)[:, 1]\n",
    "#calculate metrics\n",
    "acc_adni_test=accuracy_score(Y_test, predictions_test)\n",
    "bacc_adni_test=balanced_accuracy_score(Y_test, predictions_test)\n",
    "f1_adni_test=f1_score(Y_test, predictions_test, average='macro')\n",
    "mcc_adni_test=matthews_corrcoef(Y_test, predictions_test)\n",
    "auroc_adni_test=roc_auc_score(Y_test, predictions_test_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf3bc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load AIBL test dataset\n",
    "AIBL=pd.read_csv(path_test_AIBL,index_col=\"PTID\")\n",
    "#change format of AIBL dataset\n",
    "Y_AIBL=pd.get_dummies(AIBL.DX,drop_first=True).to_numpy().squeeze()\n",
    "X_AIBL=AIBL.drop([\"DX\"],axis=1).to_numpy()\n",
    "#apply scaling for AIBL test dataset\n",
    "X_AIBL_pre=scaler.transform(X_AIBL)\n",
    "#predict calibrated results for AIBL test set\n",
    "predictions_test = model.predict(X_AIBL_pre)\n",
    "predictions_test_prob=model.predict_proba(X_AIBL_pre)[:, 1]\n",
    "#calculate metrics for AIBL\n",
    "acc_aibl_test=accuracy_score(Y_AIBL, predictions_test)\n",
    "bacc_aibl_test=balanced_accuracy_score(Y_AIBL, predictions_test)\n",
    "f1_aibl_test=f1_score(Y_AIBL, predictions_test, average='macro')\n",
    "mcc_aibl_test=matthews_corrcoef(Y_AIBL, predictions_test)\n",
    "auroc_aibl_test=roc_auc_score(Y_AIBL, predictions_test_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db58d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load OASIS test dataset\n",
    "OASIS=pd.read_csv(path_test_OASIS,index_col=\"PTID\")\n",
    "#change format of OASIS test dataset\n",
    "Y_OASIS=pd.get_dummies(OASIS.DX,drop_first=True).to_numpy().squeeze()\n",
    "X_OASIS=OASIS.drop([\"DX\"],axis=1).to_numpy()\n",
    "#apply scaling for OASIS test dataset\n",
    "X_OASIS_pre=scaler.transform(X_OASIS)\n",
    "#predict calibrated results for OASIS test set\n",
    "predictions_test = model.predict(X_OASIS_pre)\n",
    "predictions_test_prob=model.predict_proba(X_OASIS_pre)[:, 1]\n",
    "#calculate metrics for OASIS\n",
    "acc_oasis_test=accuracy_score(Y_OASIS, predictions_test)\n",
    "bacc_oasis_test=balanced_accuracy_score(Y_OASIS,predictions_test)\n",
    "f1_oasis_test=f1_score(Y_OASIS, predictions_test, average='macro')\n",
    "mcc_oasis_test=matthews_corrcoef(Y_OASIS, predictions_test)\n",
    "auroc_oasis_test=roc_auc_score(Y_OASIS, predictions_test_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cf2c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpret ML model\n",
    "#load mapping of features between ML and DL\n",
    "mapping=pd.read_csv(mapping_ML_DL)\n",
    "#identify features which are available for both model types\n",
    "X_train_pre_red=X_train_pre[:,training.drop([\"DX\"],axis=1).columns.isin(mapping.feature_ML)]\n",
    "#identify aspects for features which are available for both model types\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dataNamed=pd.DataFrame(X_train_pre_red,columns=training.drop([\"DX\"],axis=1).columns[training.drop([\"DX\"],axis=1).columns.isin(mapping.feature_ML)])\n",
    "exp = dx.Explainer(dummy_clf, dataNamed, Y_train)\n",
    "asp = dx.Aspect(exp)\n",
    "aspects=asp.get_aspects(h=0.5)\n",
    "#add features only available in ML models (eTIV)\n",
    "notInDeep=training.drop([\"DX\"],axis=1).columns[~training.drop([\"DX\"],axis=1).columns.isin(mapping.feature_ML)]\n",
    "notInDeep=notInDeep.tolist()\n",
    "for value in notInDeep:\n",
    "    aspects[value]=[value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d9646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate permutation importance for aspects\n",
    "dataNamed=pd.DataFrame(X_train_pre,columns=training.drop([\"DX\"],axis=1).columns)\n",
    "exp = dx.Explainer(model, dataNamed, Y_train)\n",
    "asp = dx.Aspect(exp)\n",
    "mai_asp = asp.model_parts(variable_groups=aspects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63de9a1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#calculate SHAP importances for aspects\n",
    "dataNamed=pd.DataFrame(X_train_pre,columns=training.drop([\"DX\"],axis=1).columns)\n",
    "exp = dx.Explainer(model, dataNamed, Y_train)\n",
    "asp = dx.Aspect(exp)\n",
    "df=pd.DataFrame(columns=aspects.keys())\n",
    "for i in range(X_train_pre.shape[0]):\n",
    "    print(i)\n",
    "    mai_asp_shap = asp.predict_parts(X_train_pre[i],variable_groups=aspects, label='for aspects created by user', type='shap', random_state=42,N=1000)\n",
    "    res=mai_asp_shap.result\n",
    "    df=pd.concat([df,pd.DataFrame([res.importance.tolist()],columns=res.aspect_name,index=[trainValidMerged.index[i]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37355b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize SHAP feature importance plot\n",
    "df_sum=df.abs().sum(axis=0)\n",
    "ax=pd.Series(df_sum,dtype=float).nlargest(10).plot(kind='barh')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel(\"SHAP importance\")\n",
    "ax.set_ylabel(\"Aspects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9087b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize SHAP summary plot\n",
    "training_cal=trainValidMerged.copy()\n",
    "for a in aspects:\n",
    "    for b in aspects[a]:\n",
    "        training_cal[b]=df[a]\n",
    "training_cal_shap=training_cal.drop([\"DX\"],axis=1)\n",
    "training_test=trainValidMerged.drop([\"DX\"],axis=1)\n",
    "columnNamesNew=training_test.columns\n",
    "columnNamesNew=[]\n",
    "for column in trainValidMerged.columns:\n",
    "    for aspect in aspects:\n",
    "        for dfcol in aspects[aspect]:\n",
    "            if(dfcol==column):\n",
    "                if(aspect.startswith(\"aspect\")):\n",
    "                    columnNamesNew.append(column+\" (\"+aspect+\")\")\n",
    "                else:\n",
    "                    columnNamesNew.append(column)\n",
    "\n",
    "shap.summary_plot(training_cal_shap.to_numpy().astype(float),training_test.to_numpy().astype(float),columnNamesNew,show=False)\n",
    "plt.text(-0.4, 20, 'protective')\n",
    "plt.text(0.6, 20, 'progressive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b669f782",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#calculate LIME importances for aspects\n",
    "dataNamed=pd.DataFrame(X_train_pre,columns=training.drop([\"DX\"],axis=1).columns)\n",
    "exp = dx.Explainer(model, dataNamed, Y_train)\n",
    "asp = dx.Aspect(exp)\n",
    "df=pd.DataFrame(columns=aspects.keys())\n",
    "for i in range(X_train_pre.shape[0]):\n",
    "    print(i)\n",
    "    mai_asp_shap = asp.predict_parts(X_train_pre[i],variable_groups=aspects, label='for aspects created by user', type='default', random_state=42,N=1000)\n",
    "    res=mai_asp_shap.result\n",
    "    df=pd.concat([df,pd.DataFrame([res.importance.tolist()],columns=res.aspect_name,index=[trainValidMerged.index[i]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440cdf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize LIME feature importance plot\n",
    "df_sum=df.abs().sum(axis=0)\n",
    "ax=pd.Series(df_sum,dtype=float).nlargest(10).plot(kind='barh')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel(\"LIME importance\")\n",
    "ax.set_ylabel(\"Aspects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92e42c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize LIME summary plot\n",
    "training_cal=trainValidMerged.copy()\n",
    "for a in aspects:\n",
    "    for b in aspects[a]:\n",
    "        training_cal[b]=df[a]\n",
    "training_cal_shap=training_cal.drop([\"DX\"],axis=1)\n",
    "training_test=trainValidMerged.drop([\"DX\"],axis=1)\n",
    "columnNamesNew=training_test.columns\n",
    "columnNamesNew=[]\n",
    "for column in trainValidMerged.columns:\n",
    "    for aspect in aspects:\n",
    "        for dfcol in aspects[aspect]:\n",
    "            if(dfcol==column):\n",
    "                if(aspect.startswith(\"aspect\")):\n",
    "                    columnNamesNew.append(column+\" (\"+aspect+\")\")\n",
    "                else:\n",
    "                    columnNamesNew.append(column)\n",
    "\n",
    "shap.summary_plot(training_cal_shap.to_numpy().astype(float),training_test.to_numpy().astype(float),columnNamesNew,show=False)\n",
    "plt.text(-0.4, 20, 'protective')\n",
    "plt.text(0.6, 20, 'progressive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd4631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean CV-Accuracy: {round(cv_acc_mean,3)},\\n SD CV-Accuracy: {round(cv_acc_sd,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d131df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy (ADNI test set): {round(acc_adni_test*100,2)},\\n balanced-accuracy (ADNI test set): {round(bacc_adni_test*100,2)},\\n Macro-averaging F1-score (ADNI test set): {round(f1_adni_test*100,2)},\\n MCC (ADNI test set): {round(mcc_adni_test,3)},\\n AUROC (ADNI test set): {round(auroc_adni_test*100,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89ade27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy (AIBL test set): {round(acc_aibl_test*100,2)},\\n balanced-accuracy (AIBL test set): {round(bacc_aibl_test*100,2)},\\n Macro-averaging F1-score (AIBL test set): {round(f1_aibl_test*100,2)},\\n MCC (AIBL test set): {round(mcc_aibl_test,3)},\\n AUROC (AIBL test set): {round(auroc_aibl_test*100,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c108b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy (OASIS test set): {round(acc_oasis_test*100,2)},\\n balanced-accuracy (OASIS test set): {round(bacc_oasis_test*100,2)},\\n Macro-averaging F1-score (OASIS test set): {round(f1_oasis_test*100,2)},\\n MCC (OASIS test set): {round(mcc_oasis_test,3)},\\n AUROC (OASIS test set): {round(auroc_oasis_test*100,2)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
