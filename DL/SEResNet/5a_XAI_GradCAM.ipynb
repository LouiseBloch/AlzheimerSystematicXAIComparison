{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebd18f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "from livelossplot import PlotLosses\n",
    "import pickle\n",
    "import torch\n",
    "import monai\n",
    "from monai.data import DataLoader\n",
    "from monai.transforms import (\n",
    "    AddChanneld,\n",
    "    CenterSpatialCropd,\n",
    "    Compose,\n",
    "    Resized,\n",
    "    RandSpatialCropd,\n",
    "    ScaleIntensityd,\n",
    "    ToTensord,\n",
    "    LoadImaged,\n",
    "    Identityd,\n",
    ")\n",
    "from monai.utils import InterpolateMode\n",
    "import nibabel as nib\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42500f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters which were selected during hyperparameter tuning\n",
    "lr=1e-4\n",
    "opt=\"none\"\n",
    "strategy=\"adam\"\n",
    "epoch=84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd47fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definitions of path\n",
    "MODEL_DIR = os.path.join(\"./SEResNet/\")\n",
    "path_train_data=os.path.join(\"../../data/trainValid_DL.csv\")\n",
    "mapping_ML_DL=os.path.join(\"../../additional_data/Mapping_DKT_Regions_Deep_ML_new.csv\")\n",
    "aspects_filename=os.path.join(\"../../additional_data/aspects05_new.pkl\")\n",
    "freesurfer_mapping_filename=os.path.join(\"../../additional_data/freesurferMappingReduced.csv\")\n",
    "gradCAM_image_directory=os.path.join(\"./SEResNet/GradCAM/\")\n",
    "gradCAM_save_individual_results_path=os.path.join(\"./SEResNet/GradCAM/GradCAM_individual.csv\")\n",
    "gradCAM_save_global_results_path=os.path.join(\"./SEResNet/GradCAM/GradCAM_global.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522a1b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if model directory not exists create GradCAM directory\n",
    "if not os.path.exists(gradCAM_image_directory):\n",
    "    os.makedirs(gradCAM_image_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e537436",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f774fa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load training dataset\n",
    "trainValidMerged=pd.read_csv(path_train_data,index_col=\"PTID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb000bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data augmentations\n",
    "validation_transforms = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"img\",\"segmentation\"]),\n",
    "            AddChanneld(keys=[\"img\",\"segmentation\"]),\n",
    "            ScaleIntensityd(keys=[\"img\"]),\n",
    "            Resized(keys=[\"img\"],spatial_size=(256,256,256)),\n",
    "            Resized(keys=[\"segmentation\"],spatial_size=(256,256,256),mode=InterpolateMode.NEAREST),\n",
    "            CenterSpatialCropd(keys=[\"img\",\"segmentation\"],roi_size=(224,224,224)),\n",
    "            ToTensord(keys=[\"img\",\"segmentation\"]),\n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fd7e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to set seeds for reproducibility\n",
    "def set_seed(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f815998",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reformat training dataset to pytorch\n",
    "Y_train=pd.get_dummies(trainValidMerged.DX,drop_first=True).to_numpy().squeeze()\n",
    "Y_train=Y_train.tolist()\n",
    "trainDSNew = [{\"PTID\":ptid,\"img\": img, \"label\": label,\"segmentation\":segmentation} for ptid,img, label,segmentation in zip(trainValidMerged.index,trainValidMerged.filename, Y_train,trainValidMerged.filenameSeg)]\n",
    "set_seed(123)\n",
    "train_ds = monai.data.Dataset(data=trainDSNew, transform=validation_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=8, pin_memory=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e55777",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose cuda as the device if it is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#load DL model using monai\n",
    "model = monai.networks.nets.SEResNet152(num_classes=2,spatial_dims=3, in_channels=1)\n",
    "#load final model weights\n",
    "PATH=MODEL_DIR+\"model_\"+str(opt)+\"_\"+str(lr)+\"_\"+str(strategy)+\"_\"+str(epoch)+\"_final_model_polyak_averaged.pth\"\n",
    "model.load_state_dict(torch.load(PATH))  # Choose whatever GPU device number you want\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c500bc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initalize GradCAM explainer\n",
    "cam = monai.visualize.GradCAM(\n",
    "    nn_module=model, target_layers=\"layer4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4623d83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load aspects\n",
    "with open(aspects_filename, 'rb') as f:\n",
    "    aspects = pickle.load(f)\n",
    "#load ML/DL feature mapping\n",
    "mapping=pd.read_csv(mapping_ML_DL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b9b204",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load freesurfer segmentation mapping\n",
    "freesurferMapping=pd.read_table(freesurfer_mapping_filename,sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f799de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping between brain regions and freesurfer segmentation regions\n",
    "mergedDF=pd.merge(mapping,freesurferMapping,how=\"outer\",right_on=\"brain region\",left_on=\"feature_Deep\")\n",
    "#map aspects to freesurfer segmentations\n",
    "for key in aspects:\n",
    "    aspects[key]=mergedDF[mergedDF.feature_ML.isin(aspects[key])].ID.tolist()\n",
    "\n",
    "#identify brain regions not available in ML models\n",
    "notInML=freesurferMapping[~freesurferMapping[\"brain region\"].isin(mapping.feature_Deep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a915ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add brain regions without ML volumes to aspects\n",
    "for index, row in notInML.iterrows():\n",
    "    aspects[row[\"brain region\"]]=[row[\"ID\"]]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e39a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize dataframe to save activated brain regions of GradCAM map\n",
    "column_names = [\"PTID\",\"label\",\"pred\"]+list(aspects.keys())\n",
    "df = pd.DataFrame(columns = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1e0649",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexi=0\n",
    "#change model to evaluation model\n",
    "model.eval()\n",
    "#iterate over training dataset\n",
    "for val_data in train_loader:\n",
    "    indexi+=1\n",
    "    #load input scan, label and freesurfer segmentation mask of training data sample\n",
    "    img=val_data[\"img\"].cuda()\n",
    "    label=val_data[\"label\"].numpy()[0]\n",
    "    seg=val_data[\"segmentation\"].cuda()\n",
    "    #calculate model prediction for training data sample\n",
    "    pred=model(img).argmax(dim=1).cpu().detach().numpy()[0]\n",
    "    #compute GradCAM result for training sample\n",
    "    result = cam(x=img)\n",
    "    #invert GradCAM result https://docs.monai.io/en/stable/visualize.html (last accessed: 2024-01-18)\n",
    "    result=result*(-1)+1\n",
    "    #save GradCAM map to specified directory\n",
    "    result_test=np.squeeze(result.cpu().numpy())\n",
    "    result_image = nib.Nifti1Image(result_test, affine=np.eye(4))\n",
    "    nib.save(result_image, gradCAM_image_directory+\"GradCAM_PTID_\"+val_data[\"PTID\"][0]+\".nii.gz\")  \n",
    "    #flatten segmentation\n",
    "    seg_flattened=seg.flatten()\n",
    "    #generate new segmentation based on aspects\n",
    "    seg_Flattened_new=torch.zeros_like(seg_flattened)\n",
    "    i=1\n",
    "    for aspect in aspects:\n",
    "        for value in aspects[aspect]:\n",
    "            seg_Flattened_new[seg_flattened==value]=i\n",
    "        i+=1\n",
    "    #flatten GradCAM image\n",
    "    res_flattened=result.flatten()\n",
    "    #identify segmentation labels and counts\n",
    "    colors, counts = np.unique(seg_Flattened_new.cpu().detach().numpy(), axis=0, return_counts=True)\n",
    "    #initalize array to save summed values of GradCAM scores per aspect\n",
    "    summedValues=[0]*counts.shape[0]\n",
    "    summedValues=np.asarray(summedValues)\n",
    "    #calculate summed values of GradCAM scores\n",
    "    j=0\n",
    "    for i in colors:\n",
    "        summedValues[j]=res_flattened[(seg_Flattened_new==i).cpu().numpy()].sum()\n",
    "        j+=1\n",
    "    #calculate mean values of GradCAM scores\n",
    "    meanValues=summedValues/counts\n",
    "    #insert 0 values for aspects which are not segmented in the image\n",
    "    for i in range(1,len(aspects)+1):\n",
    "        if(~np.isin(i,colors)):\n",
    "            colors=np.insert(colors,i-1,i)\n",
    "            meanValues=np.insert(meanValues,i-1,0)\n",
    "            summedValues=np.insert(summedValues,i-1,0)\n",
    "            counts=np.insert(counts,i-1,0)\n",
    "    #save mean GradCAM scores for all aspects\n",
    "    d = {'ID': colors, 'meanValues': meanValues,'summedValues':summedValues, \"counts\":counts}\n",
    "    dfSub = pd.DataFrame(data=d)\n",
    "    column_names = [\"PTID\",\"label\",\"pred\"]+list(aspects.keys())\n",
    "    values=[val_data[\"PTID\"][0],label,pred]+ meanValues.tolist()\n",
    "    df2 = pd.DataFrame([values],columns = column_names)\n",
    "    df = pd.concat([df,df2],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eeeaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results at subject level\n",
    "df.to_csv(gradCAM_save_individual_results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40194853",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save global results\n",
    "df=df.drop([\"PTID\"],axis=1)\n",
    "d = {'feature': df.sum().index.tolist(), 'GradCAMImportance': df.sum().tolist()}\n",
    "resultsSum=pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b82fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsSum.to_csv(gradCAM_save_global_results_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
