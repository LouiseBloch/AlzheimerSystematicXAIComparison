{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a07229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "from livelossplot import PlotLosses\n",
    "import pickle\n",
    "import torch\n",
    "import monai\n",
    "from monai.data import DataLoader\n",
    "from monai.transforms import (\n",
    "    AddChanneld,\n",
    "    CenterSpatialCropd,\n",
    "    Compose,\n",
    "    Resized,\n",
    "    RandSpatialCropd,\n",
    "    ScaleIntensityd,\n",
    "    ToTensord,\n",
    "    LoadImaged,\n",
    "    Identityd,\n",
    ")\n",
    "from monai.utils import InterpolateMode\n",
    "import nibabel as nib\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a14c0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters which were selected during hyperparameter tuning\n",
    "lr=1e-4\n",
    "opt=\"none\"\n",
    "strategy=\"adam\"\n",
    "epoch=31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6f7862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definitions of path\n",
    "MODEL_DIR = os.path.join(\"./DenseNet/\")\n",
    "path_train_data=os.path.join(\"../../data/trainValid_DL.csv\")\n",
    "mapping_ML_DL=os.path.join(\"../../additional_data/Mapping_DKT_Regions_Deep_ML_new.csv\")\n",
    "aspects_filename=os.path.join(\"../../additional_data/aspects05_new.pkl\")\n",
    "freesurfer_mapping_filename=os.path.join(\"../../additional_data/freesurferMappingReduced.csv\")\n",
    "gradCAMpp_image_directory=os.path.join(\"./DenseNet/GradCAMpp/\")\n",
    "gradCAMpp_save_individual_results_path=os.path.join(\"./DenseNet/GradCAMpp/GradCAMpp_individual.csv\")\n",
    "gradCAMpp_save_global_results_path=os.path.join(\"./DenseNet/GradCAMpp/GradCAMpp_global.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c373c5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if model directory not exists create GradCAMpp directory\n",
    "if not os.path.exists(gradCAMpp_image_directory):\n",
    "    os.makedirs(gradCAMpp_image_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525b179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28942497",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load training dataset\n",
    "trainValidMerged=pd.read_csv(path_train_data,index_col=\"PTID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b059a597",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data augmentations\n",
    "validation_transforms = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"img\",\"segmentation\"]),\n",
    "            AddChanneld(keys=[\"img\",\"segmentation\"]),\n",
    "            ScaleIntensityd(keys=[\"img\"]),\n",
    "            Resized(keys=[\"img\"],spatial_size=(256,256,256)),\n",
    "            Resized(keys=[\"segmentation\"],spatial_size=(256,256,256),mode=InterpolateMode.NEAREST),\n",
    "            CenterSpatialCropd(keys=[\"img\",\"segmentation\"],roi_size=(224,224,224)),\n",
    "            ToTensord(keys=[\"img\",\"segmentation\"]),\n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c29781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to set seeds for reproducibility\n",
    "def set_seed(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fcd0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reformat training dataset to pytorch\n",
    "Y_train=pd.get_dummies(trainValidMerged.DX,drop_first=True).to_numpy().squeeze()\n",
    "Y_train=Y_train.tolist()\n",
    "trainDSNew = [{\"PTID\":ptid,\"img\": img, \"label\": label,\"segmentation\":segmentation} for ptid,img, label,segmentation in zip(trainValidMerged.index,trainValidMerged.filename, Y_train,trainValidMerged.filenameSeg)]\n",
    "set_seed(123)\n",
    "train_ds = monai.data.Dataset(data=trainDSNew, transform=validation_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=8, pin_memory=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a9a01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose cuda as the device if it is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#load DL model using monai\n",
    "model = monai.networks.nets.densenet121(spatial_dims=3, in_channels=1, out_channels=2)\n",
    "#load final model weights\n",
    "PATH=MODEL_DIR+\"model_\"+str(opt)+\"_\"+str(lr)+\"_\"+str(strategy)+\"_\"+str(epoch)+\"_final_model_polyak_averaged.pth\"\n",
    "model.load_state_dict(torch.load(PATH))  # Choose whatever GPU device number you want\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218f2697",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initalize GradCAMpp explainer\n",
    "cam = monai.visualize.GradCAMpp(\n",
    "    nn_module=model, target_layers=\"class_layers.relu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862e444a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load aspects\n",
    "with open(aspects_filename, 'rb') as f:\n",
    "    aspects = pickle.load(f)\n",
    "#load ML/DL feature mapping\n",
    "mapping=pd.read_csv(mapping_ML_DL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a831465",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load freesurfer segmentation mapping\n",
    "freesurferMapping=pd.read_table(freesurfer_mapping_filename,sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276fe71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping between brain regions and freesurfer segmentation regions\n",
    "mergedDF=pd.merge(mapping,freesurferMapping,how=\"outer\",right_on=\"brain region\",left_on=\"feature_Deep\")\n",
    "#map aspects to freesurfer segmentations\n",
    "for key in aspects:\n",
    "    aspects[key]=mergedDF[mergedDF.feature_ML.isin(aspects[key])].ID.tolist()\n",
    "\n",
    "#identify brain regions not available in ML models\n",
    "notInML=freesurferMapping[~freesurferMapping[\"brain region\"].isin(mapping.feature_Deep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab6c69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add brain regions without ML volumes to aspects\n",
    "for index, row in notInML.iterrows():\n",
    "    aspects[row[\"brain region\"]]=[row[\"ID\"]]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287301d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize dataframe to save activated brain regions of GradCAMpp map\n",
    "column_names = [\"PTID\",\"label\",\"pred\"]+list(aspects.keys())\n",
    "df = pd.DataFrame(columns = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d089195",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexi=0\n",
    "model.eval()\n",
    "#change model to evaluation model\n",
    "for val_data in train_loader:\n",
    "    indexi+=1\n",
    "    #load input scan, label and freesurfer segmentation mask of training data sample\n",
    "    img=val_data[\"img\"].cuda()\n",
    "    label=val_data[\"label\"].numpy()[0]\n",
    "    seg=val_data[\"segmentation\"].cuda()\n",
    "    #calculate model prediction for training data sample\n",
    "    pred=model(img).argmax(dim=1).cpu().detach().numpy()[0]\n",
    "    #compute GradCAMpp result for training sample\n",
    "    result = cam(x=img)\n",
    "    #invert GradCAMpp result https://docs.monai.io/en/stable/visualize.html (last accessed: 2024-01-18)\n",
    "    result=result*(-1)+1\n",
    "    #save GradCAMpp map to specified directory\n",
    "    result_test=np.squeeze(result.cpu().numpy())\n",
    "    result_image = nib.Nifti1Image(result_test, affine=np.eye(4))\n",
    "    nib.save(result_image, gradCAMpp_image_directory+\"GradCAMpp_PTID_\"+val_data[\"PTID\"][0]+\".nii.gz\")  \n",
    "    #flatten segmentation\n",
    "    seg_flattened=seg.flatten()\n",
    "    #generate new segmentation based on aspects\n",
    "    seg_Flattened_new=torch.zeros_like(seg_flattened)\n",
    "    i=1\n",
    "    for aspect in aspects:\n",
    "        for value in aspects[aspect]:\n",
    "            seg_Flattened_new[seg_flattened==value]=i\n",
    "        i+=1\n",
    "    #flatten GradCAMpp image\n",
    "    res_flattened=result.flatten()\n",
    "    #identify segmentation labels and counts\n",
    "    colors, counts = np.unique(seg_Flattened_new.cpu().detach().numpy(), axis=0, return_counts=True)\n",
    "    #initalize array to save summed values of GradCAMpp scores per aspect\n",
    "    summedValues=[0]*counts.shape[0]\n",
    "    summedValues=np.asarray(summedValues)\n",
    "    #calculate summed values of GradCAMpp scores\n",
    "    j=0\n",
    "    for i in colors:\n",
    "        summedValues[j]=res_flattened[(seg_Flattened_new==i).cpu().numpy()].sum()\n",
    "        j+=1\n",
    "    #calculate mean values of GradCAMpp scores\n",
    "    meanValues=summedValues/counts\n",
    "    #insert 0 values for aspects which are not segmented in the image\n",
    "    for i in range(1,len(aspects)+1):\n",
    "        if(~np.isin(i,colors)):\n",
    "            colors=np.insert(colors,i-1,i)\n",
    "            meanValues=np.insert(meanValues,i-1,0)\n",
    "            summedValues=np.insert(summedValues,i-1,0)\n",
    "            counts=np.insert(counts,i-1,0)\n",
    "    #save mean GradCAMpp scores for all aspects\n",
    "    d = {'ID': colors, 'meanValues': meanValues,'summedValues':summedValues, \"counts\":counts}\n",
    "    dfSub = pd.DataFrame(data=d)\n",
    "    column_names = [\"PTID\",\"label\",\"pred\"]+list(aspects.keys())\n",
    "    values=[val_data[\"PTID\"][0],label,pred]+ meanValues.tolist()\n",
    "    df2 = pd.DataFrame([values],columns = column_names)\n",
    "    df = pd.concat([df,df2],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d5474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results at subject level\n",
    "df.to_csv(gradCAMpp_save_individual_results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1a2035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save global results\n",
    "df=df.drop([\"PTID\"],axis=1)\n",
    "d = {'feature': df.sum().index.tolist(), 'GradCAMppImportance': df.sum().tolist()}\n",
    "resultsSum=pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b59eb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsSum.to_csv(gradCAMpp_save_global_results_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
