{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f143724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "from livelossplot import PlotLosses\n",
    "import pickle\n",
    "import torch\n",
    "import monai\n",
    "from monai.data import DataLoader\n",
    "from monai.transforms import (\n",
    "    AddChanneld,\n",
    "    CenterSpatialCropd,\n",
    "    Compose,\n",
    "    Resized,\n",
    "    RandSpatialCropd,\n",
    "    ScaleIntensityd,\n",
    "    ToTensord,\n",
    "    LoadImaged,\n",
    "    Identityd,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from monai.utils import InterpolateMode\n",
    "import nibabel as nib\n",
    "import shap\n",
    "from skimage.segmentation import slic\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2398a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters which were selected during hyperparameter tuning\n",
    "lr=1e-2\n",
    "opt=\"none\"\n",
    "strategy=\"adam\"\n",
    "epoch=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9e9f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definitions of path\n",
    "MODEL_DIR = os.path.join(\"./DenseNet_pretrained/\")\n",
    "path_train_data=os.path.join(\"../../data/trainValid_DL.csv\")\n",
    "filename_predictions_for_platt_scaling=os.path.join(\"./DenseNet_pretrained/predictions_for_platt_scaling.csv\")\n",
    "mapping_ML_DL=os.path.join(\"../../additional_data/Mapping_DKT_Regions_Deep_ML_new.csv\")\n",
    "aspects_filename=os.path.join(\"../../additional_data/aspects05_new.pkl\")\n",
    "freesurfer_mapping_filename=os.path.join(\"../../additional_data/freesurferMappingReduced.csv\")\n",
    "SHAP_image_directory=os.path.join(\"./DenseNet_pretrained/SHAP/\")\n",
    "SHAP_save_individual_results_path=os.path.join(\"./DenseNet_pretrained/SHAP/SHAP_individual.csv\")\n",
    "SHAP_save_global_results_path=os.path.join(\"./DenseNet_pretrained/SHAP/SHAP_global.csv\")\n",
    "mean_values_for_brain_regions_file=os.path.join('../../additional_data/meanRegionValueCNAD_new.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b929e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if model directory not exists create SHAP directory\n",
    "if not os.path.exists(SHAP_image_directory):\n",
    "    os.makedirs(SHAP_image_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70901b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5680c258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load training dataset\n",
    "trainValidMerged=pd.read_csv(path_train_data,index_col=\"PTID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d83ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data augmentations\n",
    "validation_transforms = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"img\",\"segmentation\"]),\n",
    "            AddChanneld(keys=[\"img\",\"segmentation\"]),\n",
    "            ScaleIntensityd(keys=[\"img\"]),\n",
    "            Resized(keys=[\"img\"],spatial_size=(256,256,256)),\n",
    "            Resized(keys=[\"segmentation\"],spatial_size=(256,256,256),mode=InterpolateMode.NEAREST),\n",
    "            CenterSpatialCropd(keys=[\"img\",\"segmentation\"],roi_size=(224,224,224)),\n",
    "            ToTensord(keys=[\"img\",\"segmentation\"]),\n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e92927",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to set seeds for reproducibility\n",
    "def set_seed(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011dbeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train Logistic Regression model for Platt's scaling\n",
    "pred = pd.read_csv(filename_predictions_for_platt_scaling)\n",
    "predictions = np.expand_dims(pred.predictions.to_numpy(), axis=1)\n",
    "clf = LogisticRegression(random_state=0).fit(predictions, pred.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7af4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reformat training dataset to pytorch\n",
    "Y_train=pd.get_dummies(trainValidMerged.DX,drop_first=True).to_numpy().squeeze()\n",
    "Y_train=Y_train.tolist()\n",
    "trainDSNew = [{\"PTID\":ptid,\"img\": img, \"label\": label,\"segmentation\":segmentation} for ptid,img, label,segmentation in zip(trainValidMerged.index,trainValidMerged.filename, Y_train,trainValidMerged.filenameSeg)]\n",
    "set_seed(123)\n",
    "train_ds = monai.data.Dataset(data=trainDSNew, transform=validation_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=8, pin_memory=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c984c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose cuda as the device if it is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#load DL model using monai\n",
    "model = monai.networks.nets.densenet121(spatial_dims=3, in_channels=1, out_channels=2)\n",
    "#load final model weights\n",
    "PATH=MODEL_DIR+\"model_\"+str(opt)+\"_\"+str(lr)+\"_\"+str(strategy)+\"_\"+str(epoch)+\"_final_model_polyak_averaged.pth\"\n",
    "model.load_state_dict(torch.load(PATH))  # Choose whatever GPU device number you want\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e679c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load mean intensities for brain regions\n",
    "with open(mean_values_for_brain_regions_file, 'rb') as f:\n",
    "    meanReg = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d33f54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function how to mask the image during SHAP computation (masking with mean intensity image for aspects)\n",
    "def mask_image(zs, segmentation, image,colors):\n",
    "    maskIds= np.where(zs==0)[0]\n",
    "    colorMask=colors[maskIds]\n",
    "    mask = torch.isin(segmentation, colorMask)\n",
    "    out=image.clone()\n",
    "    out[mask]=meanImg[mask]\n",
    "    return out\n",
    "#define function to iterate over all SHAP entries which should be considered, apply masking and calculate predictions\n",
    "def shapFunc(z):\n",
    "    preds=[]\n",
    "    index_i=0\n",
    "    #iterate over SHAP entries\n",
    "    for znew in z:\n",
    "        set_seed(123)\n",
    "        index_i+=1\n",
    "        #calculate prediction of masked image\n",
    "        pred=model(mask_image(znew,segmentation,img,torch.unique(segmentation)))\n",
    "        pred=torch.nn.functional.softmax(pred,dim=1)\n",
    "        pred=pred.cpu().detach().numpy()[:,1]\n",
    "        pred=np.expand_dims(pred, axis=1)\n",
    "        #calculate calibrated results\n",
    "        pred=clf.predict_proba(pred)\n",
    "        preds.append(pred.tolist())\n",
    "    preds=np.array(preds)\n",
    "    preds=preds[:,0,1]\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafe9f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e786a605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b428c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load aspects\n",
    "with open(aspects_filename, 'rb') as f:\n",
    "    aspects = pickle.load(f)\n",
    "#load ML/DL feature mapping\n",
    "mapping=pd.read_csv(mapping_ML_DL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad10f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load freesurfer segmentation mapping\n",
    "freesurferMapping=pd.read_table(freesurfer_mapping_filename,sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daba80ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify all FreeSurfer segmented regions\n",
    "colorsF = freesurferMapping.ID.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27b4d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping between brain regions and freesurfer segmentation regions\n",
    "mergedDF=pd.merge(mapping,freesurferMapping,how=\"outer\",right_on=\"brain region\",left_on=\"feature_Deep\")\n",
    "#map aspects to freesurfer segmentations\n",
    "for key in aspects:\n",
    "    aspects[key]=mergedDF[mergedDF.feature_ML.isin(aspects[key])].ID.tolist()\n",
    "\n",
    "#identify brain regions not available in ML models\n",
    "notInML=freesurferMapping[~freesurferMapping[\"brain region\"].isin(mapping.feature_Deep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878dd7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add brain regions without ML volumes to aspects\n",
    "for index, row in notInML.iterrows():\n",
    "    aspects[row[\"brain region\"]]=[row[\"ID\"]]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fb07be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize dataframe to save activated brain regions of GradCAM map\n",
    "column_names = [\"PTID\",\"label\",\"pred\"]+list(aspects.keys())\n",
    "df = pd.DataFrame(columns = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bfdf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_i=0\n",
    "#change model to evaluation model\n",
    "model.eval()\n",
    "#iterate over training dataset\n",
    "for data in train_loader:\n",
    "    print(index_i)\n",
    "    #load input scans, segmentation PTID and label\n",
    "    img=data[\"img\"]\n",
    "    segmentationImg=data[\"segmentation\"]\n",
    "    PTID=data[\"PTID\"]\n",
    "    label=data[\"label\"].cpu().detach().numpy()[0]\n",
    "    #convert input to numpy format to apply slic for segmenting similar sized structures\n",
    "    imgSeg=np.squeeze(img.numpy())\n",
    "    #apply slic algorithm for segmentation\n",
    "    segmentation = slic(imgSeg, n_segments=100, compactness=1,channel_axis=None,start_label=0)\n",
    "    #expand dimentions for consistency with original pytorch MRI scans\n",
    "    segmentation=np.expand_dims(segmentation,axis=0)\n",
    "    segmentation=np.expand_dims(segmentation,axis=0)\n",
    "    img=img.cuda()\n",
    "    #calculate model prediction\n",
    "    pred=model(img)\n",
    "    pred=torch.nn.functional.softmax(pred,dim=1)\n",
    "    pred=pred.cpu().detach().numpy()[0,1]\n",
    "    #initalize image with mean value for all brain regions for SHAP masking\n",
    "    meanImg=np.zeros_like(segmentationImg)\n",
    "    i=0\n",
    "    #compute image with mean value for all brain regions for SHAP masking\n",
    "    for color in colorsF:\n",
    "        maskSeg=mask = np.isin(segmentationImg, color)\n",
    "        maskSeg= torch.from_numpy(maskSeg)\n",
    "        meanImg[maskSeg]=meanReg[i]\n",
    "        i+=1\n",
    "    #convert mean image to pytorch\n",
    "    meanImg=torch.from_numpy(meanImg)\n",
    "    meanImg=meanImg.type(torch.float32)\n",
    "    meanImg=meanImg.cuda()\n",
    "    #convert slic segmentation to pytorch\n",
    "    segmentation=torch.from_numpy(segmentation)\n",
    "    segmentation=segmentation.type(torch.float32)\n",
    "    segmentation=segmentation.cuda()\n",
    "    set_seed(123)\n",
    "    #calculate SHAP values for slic segmentation\n",
    "    explainer = shap.KernelExplainer(shapFunc, np.zeros((1,torch.unique(segmentation).shape[0])),silent=True)\n",
    "    shap_values = explainer.shap_values(np.ones((1,torch.unique(segmentation).shape[0])), nsamples=1000) # runs VGG16 1000 times\n",
    "    #initialize image containing SHAP values for each pixel in dependence of the slic segmentations\n",
    "    out=np.zeros(img.shape)\n",
    "    #compute image containing SHAP values for each pixel in dependence of the slic segmentations\n",
    "    for i in range(shap_values[0].shape[0]):\n",
    "        region=(segmentation==i)\n",
    "        out[region.cpu().detach().numpy()]=shap_values[0][i]\n",
    "    #save image containing SHAP values as nifti file\n",
    "    result_test=np.squeeze(out)\n",
    "    result_image = nib.Nifti1Image(result_test, affine=np.eye(4))\n",
    "    nib.save(result_image, SHAP_image_directory+\"SHAP_PTID_\"+PTID[0]+\".nii.gz\")\n",
    "    #flatten FreeSurfer segmentation\n",
    "    seg_flattened=segmentationImg.flatten()\n",
    "    #generate new segmentation based on aspects\n",
    "    seg_Flattened_new=np.zeros(seg_flattened.shape)\n",
    "    i=1\n",
    "    for aspect in aspects:\n",
    "        for value in aspects[aspect]:\n",
    "            seg_Flattened_new[seg_flattened==value]=i\n",
    "        i+=1\n",
    "    #flatten SHAP image\n",
    "    out_Flattened=out.flatten()\n",
    "    #identify segmentation labels and counts\n",
    "    colors, counts = np.unique(seg_Flattened_new, axis=0, return_counts=True)\n",
    "    #initalize array to save summed values of SHAP scores per aspect\n",
    "    summedValues=[0.0]*len(aspects)\n",
    "    summedValues=np.asarray(summedValues)\n",
    "    j=0\n",
    "    #calculate summed values of SHAP scores\n",
    "    for i in range(1,len(aspects)+1):\n",
    "        summedValues[j]=out_Flattened[seg_Flattened_new==i].sum()\n",
    "        if (seg_Flattened_new==i).sum()==0:\n",
    "            counts=np.insert(counts,j,1)\n",
    "        j+=1\n",
    "    #calculate mean values of SHAP scores\n",
    "    meanValues=summedValues/counts\n",
    "    #save mean SHAP scores for all aspects\n",
    "    dfSub = pd.DataFrame({\"shap_values\":meanValues,\"aspects\":list(aspects.keys())})\n",
    "    column_names = [\"PTID\",\"label\",\"pred\"]+dfSub.aspects.to_numpy().tolist()\n",
    "    values=[PTID[0],label,pred]+dfSub[\"shap_values\"].to_numpy().tolist()\n",
    "    df2 = pd.DataFrame([values],columns = column_names)\n",
    "    df=df.append(df2, ignore_index=True)\n",
    "    index_i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d34f4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsSum.sort_values(\"SHAPImportance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4420603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results at subject level\n",
    "df.to_csv(SHAP_save_individual_results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9330ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save global results\n",
    "df=df.drop([\"PTID\"],axis=1)\n",
    "d = {'feature': df.abs().sum().index.tolist(), 'SHAPImportance': df.abs().sum().tolist()}\n",
    "resultsSum=pd.DataFrame(data=d)\n",
    "resultsSum.to_csv(SHAP_save_global_results_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
