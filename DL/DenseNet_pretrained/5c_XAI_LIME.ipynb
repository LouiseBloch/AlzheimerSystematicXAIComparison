{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34befd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "from livelossplot import PlotLosses\n",
    "import pickle\n",
    "import torch\n",
    "import monai\n",
    "import time\n",
    "from monai.data import DataLoader\n",
    "from monai.transforms import (\n",
    "    AddChanneld,\n",
    "    CenterSpatialCropd,\n",
    "    Compose,\n",
    "    Resized,\n",
    "    RandSpatialCropd,\n",
    "    ScaleIntensityd,\n",
    "    ToTensord,\n",
    "    LoadImaged,\n",
    "    Identityd,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from monai.utils import InterpolateMode\n",
    "import nibabel as nib\n",
    "import lime.lime_tabular\n",
    "from skimage.segmentation import slic\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3254ad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters which were selected during hyperparameter tuning\n",
    "lr=1e-2\n",
    "opt=\"none\"\n",
    "strategy=\"adam\"\n",
    "epoch=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d10404",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definitions of paths\n",
    "MODEL_DIR = os.path.join(\"./DenseNet_pretrained/\")\n",
    "path_train_data=os.path.join(\"../../data/trainValid_DL.csv\")\n",
    "filename_predictions_for_platt_scaling=os.path.join(\"./DenseNet_pretrained/predictions_for_platt_scaling.csv\")\n",
    "mapping_ML_DL=os.path.join(\"../../additional_data/Mapping_DKT_Regions_Deep_ML_new.csv\")\n",
    "aspects_filename=os.path.join(\"../../additional_data/aspects05_new.pkl\")\n",
    "freesurfer_mapping_filename=os.path.join(\"../../additional_data/freesurferMappingReduced.csv\")\n",
    "LIME_image_directory=os.path.join(\"./DenseNet_pretrained/LIME/\")\n",
    "LIME_save_individual_results_path=os.path.join(\"./DenseNet_pretrained/LIME/LIME_individual.csv\")\n",
    "LIME_save_global_results_path=os.path.join(\"./DenseNet_pretrained/LIME/LIME_global.csv\")\n",
    "mean_values_for_brain_regions_file=os.path.join('../../additional_data/meanRegionValueCNAD_new.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81da945e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if model directory not exists create LIME directory\n",
    "if not os.path.exists(LIME_image_directory):\n",
    "    os.makedirs(LIME_image_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52256635",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c83896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load training dataset\n",
    "trainValidMerged=pd.read_csv(path_train_data,index_col=\"PTID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2942f1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data augmentations\n",
    "validation_transforms = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"img\",\"segmentation\"]),\n",
    "            AddChanneld(keys=[\"img\",\"segmentation\"]),\n",
    "            ScaleIntensityd(keys=[\"img\"]),\n",
    "            Resized(keys=[\"img\"],spatial_size=(256,256,256)),\n",
    "            Resized(keys=[\"segmentation\"],spatial_size=(256,256,256),mode=InterpolateMode.NEAREST),\n",
    "            CenterSpatialCropd(keys=[\"img\",\"segmentation\"],roi_size=(224,224,224)),\n",
    "            ToTensord(keys=[\"img\",\"segmentation\"]),\n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20df46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to set seeds for reproducibility\n",
    "def set_seed(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922c3ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train Logistic Regression model for Platt's scaling\n",
    "pred = pd.read_csv(filename_predictions_for_platt_scaling)\n",
    "predictions = np.expand_dims(pred.predictions.to_numpy(), axis=1)\n",
    "clf = LogisticRegression(random_state=0).fit(predictions, pred.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48426d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reformat training dataset to pytorch\n",
    "Y_train=pd.get_dummies(trainValidMerged.DX,drop_first=True).to_numpy().squeeze()\n",
    "Y_train=Y_train.tolist()\n",
    "trainDSNew = [{\"PTID\":ptid,\"img\": img, \"label\": label,\"segmentation\":segmentation} for ptid,img, label,segmentation in zip(trainValidMerged.index,trainValidMerged.filename, Y_train,trainValidMerged.filenameSeg)]\n",
    "set_seed(123)\n",
    "train_ds = monai.data.Dataset(data=trainDSNew, transform=validation_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=8, pin_memory=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ebf9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose cuda as the device if it is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#load DL model using monai\n",
    "model = monai.networks.nets.densenet121(spatial_dims=3, in_channels=1, out_channels=2)\n",
    "#load final model weights\n",
    "PATH=MODEL_DIR+\"model_\"+str(opt)+\"_\"+str(lr)+\"_\"+str(strategy)+\"_\"+str(epoch)+\"_final_model_polyak_averaged.pth\"\n",
    "model.load_state_dict(torch.load(PATH))  # Choose whatever GPU device number you want\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231b7c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load mean intensities for brain regions\n",
    "with open(mean_values_for_brain_regions_file, 'rb') as f:\n",
    "    meanReg = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f1e34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function how to mask the image during LIME computation (masking with mean intensity image for aspects)\n",
    "def mask_image(zs, segmentation, image,colors):\n",
    "    maskIds= np.where(zs==0)[0]\n",
    "    colorMask=colors[maskIds]\n",
    "    mask = torch.isin(segmentation, colorMask)\n",
    "    out=image.clone()\n",
    "    out[mask]=meanImg[mask]\n",
    "    return out\n",
    "#define function to iterate over all LIME entries which should be considered, apply masking and calculate predictions\n",
    "def funcLime(z):\n",
    "    preds=[]\n",
    "    index_i=0 \n",
    "    #iterate over LIME entries\n",
    "    for znew in z:\n",
    "        set_seed(123)\n",
    "        index_i+=1\n",
    "        #calculate prediction of masked image\n",
    "        pred=model(mask_image(znew,segmentation,img,torch.unique(segmentation)))\n",
    "        pred=torch.nn.functional.softmax(pred,dim=1)\n",
    "        pred=pred.cpu().detach().numpy()[:,1]\n",
    "        pred=np.expand_dims(pred, axis=1)\n",
    "        #calculate calibrated results\n",
    "        pred=clf.predict_proba(pred)\n",
    "        preds.append(pred.tolist())\n",
    "    preds=np.array(preds)\n",
    "    preds=preds[:,0]\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2b8254",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load aspects\n",
    "with open(aspects_filename, 'rb') as f:\n",
    "    aspects = pickle.load(f)\n",
    "#load ML/DL feature mapping\n",
    "mapping=pd.read_csv(mapping_ML_DL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abdf209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load freesurfer segmentation mapping\n",
    "freesurferMapping=pd.read_table(freesurfer_mapping_filename,sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cded37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify all FreeSurfer segmented regions\n",
    "colorsF = freesurferMapping.ID.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41cc367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping between brain regions and freesurfer segmentation regions\n",
    "mergedDF=pd.merge(mapping,freesurferMapping,how=\"outer\",right_on=\"brain region\",left_on=\"feature_Deep\")\n",
    "#map aspects to freesurfer segmentations\n",
    "for key in aspects:\n",
    "    aspects[key]=mergedDF[mergedDF.feature_ML.isin(aspects[key])].ID.tolist()\n",
    "\n",
    "#identify brain regions not available in ML models\n",
    "notInML=freesurferMapping[~freesurferMapping[\"brain region\"].isin(mapping.feature_Deep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fed3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add brain regions without ML volumes to aspects\n",
    "for index, row in notInML.iterrows():\n",
    "    aspects[row[\"brain region\"]]=[row[\"ID\"]]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00d8479",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize dataframe to save activated brain regions of GradCAM map\n",
    "column_names = [\"PTID\",\"label\",\"pred\"]+list(aspects.keys())\n",
    "df = pd.DataFrame(columns = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7204fa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_i=0\n",
    "#change model to evaluation model\n",
    "model.eval()    \n",
    "#iterate over training dataset\n",
    "for data in train_loader:\n",
    "    #store starting time of subject LIME calculation\n",
    "    start = time.time()\n",
    "    index_i+=1\n",
    "    print(index_i)\n",
    "    #load input scans, segmentation PTID and label\n",
    "    img=data[\"img\"]\n",
    "    PTID=data[\"PTID\"]\n",
    "    segmentationImg=data[\"segmentation\"]\n",
    "    label=data[\"label\"].cpu().detach().numpy()[0]\n",
    "    #convert input to numpy format to apply slic for segmenting similar sized structures\n",
    "    imgSeg=np.squeeze(img.numpy())\n",
    "    #apply slic algorithm for segmentation\n",
    "    segmentation = slic(imgSeg, n_segments=100, compactness=1,channel_axis=None,start_label=0)\n",
    "    #expand dimentions for consistency with original pytorch MRI scans\n",
    "    segmentation=np.expand_dims(segmentation,axis=0)\n",
    "    segmentation=np.expand_dims(segmentation,axis=0)\n",
    "    img=img.cuda()\n",
    "    #calculate model prediction\n",
    "    pred=model(img)\n",
    "    pred=torch.nn.functional.softmax(pred,dim=1)\n",
    "    pred=pred.cpu().detach().numpy()[0,1]\n",
    "    #initalize image with mean value for all brain regions for LIME masking\n",
    "    meanImg=np.zeros_like(segmentationImg)\n",
    "    i=0\n",
    "    #compute image with mean value for all brain regions for LIME masking\n",
    "    for color in colorsF:\n",
    "        maskSeg=mask = np.isin(segmentationImg, color)\n",
    "        maskSeg= torch.from_numpy(maskSeg)\n",
    "        meanImg[maskSeg]=meanReg[i]\n",
    "        i+=1\n",
    "    #convert mean image to pytorch\n",
    "    meanImg=torch.from_numpy(meanImg)\n",
    "    meanImg=meanImg.type(torch.float32)\n",
    "    meanImg=meanImg.cuda()\n",
    "    #convert slic segmentation to pytorch\n",
    "    segmentation=torch.from_numpy(segmentation)\n",
    "    segmentation=segmentation.type(torch.float32)\n",
    "    segmentation=segmentation.cuda()\n",
    "    #generate training dataset, with zeros and ones for all slic segmentations to initialize range of values\n",
    "    train=np.array([np.zeros(torch.unique(segmentation).shape[0]),np.ones(torch.unique(segmentation).shape[0])])\n",
    "    set_seed(123)\n",
    "    #calculate LIME values for slic segmentation\n",
    "    explainer = lime.lime_tabular.LimeTabularExplainer(train, categorical_features=range(0,torch.unique(segmentation).shape[0]),random_state=423)\n",
    "    exp = explainer.explain_instance(np.ones((torch.unique(segmentation).shape[0])), funcLime,num_samples=1000,num_features=(torch.unique(segmentation).shape[0]))\n",
    "    #sort explanations by segmentation\n",
    "    sorted_by_second = sorted(exp.as_map()[1], key=lambda tup: tup[0])\n",
    "    #extract LIME explanations for each slic segmentation region\n",
    "    first_tuple_elements = [a_tuple[1] for a_tuple in sorted_by_second]\n",
    "    #initialize image containing LIME values for each pixel in dependence of the slic segmentations\n",
    "    out=np.zeros(img.shape)\n",
    "    #compute image containing LIME values for each pixel in dependence of the slic segmentations\n",
    "    for i in range(len(first_tuple_elements)):\n",
    "        region=(segmentation==i)\n",
    "        out[region.cpu().detach().numpy()]=first_tuple_elements[i]\n",
    "    #save image containing LIME values as nifti file\n",
    "    result_test=np.squeeze(out)\n",
    "    result_image = nib.Nifti1Image(result_test, affine=np.eye(4))\n",
    "    nib.save(result_image,LIME_image_directory+\"/LIME_PTID_\"+PTID[0]+\".nii.gz\")\n",
    "    #flatten FreeSurfer segmentation\n",
    "    seg_flattened=segmentationImg.flatten()\n",
    "    #generate new segmentation based on aspects\n",
    "    seg_Flattened_new=np.zeros(seg_flattened.shape)\n",
    "    i=1\n",
    "    for aspect in aspects:\n",
    "        for value in aspects[aspect]:\n",
    "            seg_Flattened_new[seg_flattened==value]=i\n",
    "        i+=1\n",
    "    #flatten LIME image\n",
    "    out_Flattened=out.flatten()\n",
    "    #identify segmentation labels and counts\n",
    "    colors, counts = np.unique(seg_Flattened_new, axis=0, return_counts=True)\n",
    "    #initalize array to save summed values of LIME scores per aspect\n",
    "    summedValues=[0.0]*len(aspects)\n",
    "    summedValues=np.asarray(summedValues)\n",
    "    j=0\n",
    "    #calculate summed values of LIME scores\n",
    "    for i in range(1,len(aspects)+1):\n",
    "        summedValues[j]=out_Flattened[seg_Flattened_new==i].sum()\n",
    "        if (seg_Flattened_new==i).sum()==0:\n",
    "            counts=np.insert(counts,j,1)\n",
    "        j+=1\n",
    "    #calculate mean values of LIME scores\n",
    "    meanValues=summedValues/counts\n",
    "    #save mean LIME scores for all aspects\n",
    "    d = {'ID': list(aspects.keys()), 'lime_values': meanValues}\n",
    "    dfSub = pd.DataFrame(data=d)\n",
    "    column_names = [\"PTID\",\"label\",\"pred\"]+list(aspects.keys())\n",
    "    values=[PTID[0],label,pred]+meanValues.tolist()\n",
    "    df2 = pd.DataFrame([values],columns = column_names)\n",
    "    df=pd.concat([df,df2],ignore_index=True)\n",
    "    end = time.time()\n",
    "    print(format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d62798",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results at subject level\n",
    "df.to_csv(LIME_save_individual_results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8e9e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save global results\n",
    "df=df.drop([\"PTID\"],axis=1)\n",
    "d = {'feature': df.abs().sum().index.tolist(), 'LIMEImportance': df.abs().sum().tolist()}\n",
    "resultsSum=pd.DataFrame(data=d)\n",
    "resultsSum.to_csv(LIME_save_global_results_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
